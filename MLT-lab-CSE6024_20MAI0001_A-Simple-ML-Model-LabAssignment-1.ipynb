{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLT-Lab-CSE6024_Lab-Assignment-1:\n",
    "    A Simple ML Model\n",
    "    \n",
    "Submitted By: 20MAI0001 - NIHARIKA   MAITRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Git Repo link: https://github.com/Niharika-20-MAI-01/Winter-2021-MLTechniques-LabCSE6024-Niharika-20MAI01/blob/main/MLT-lab-CSE6024_20MAI0001_A-Simple-ML-Model-LabAssignment-1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessay Libraries and Packages\n",
    "import sklearn.datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading our Input Dataset in Jupyter Notebook\n",
    "cancer_ds = sklearn.datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizing the loaded dataset as X (Feature Vector) and Y (Target Variable)\n",
    "X = cancer_ds.data\n",
    "Y = cancer_ds.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape) #569 rows 30 columns present in Feature Vector(X) and 569 rows present in Target Variable(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the dataset inside a dataframe using Pandas Library\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(cancer_ds.data, columns = cancer_ds.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Rename the Y variable as Target\n",
    "data['class'] = cancer_ds.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  class  \n",
       "0          0.4601                  0.11890      0  \n",
       "1          0.2750                  0.08902      0  \n",
       "2          0.3613                  0.08758      0  \n",
       "3          0.6638                  0.17300      0  \n",
       "4          0.2364                  0.07678      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To examine the first few records of our Input dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension       class  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describing each row of the Dataset including both Feature Vector(X) and Target(Y) in terms of different Statistical measures/parameters\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    357\n",
      "0    212\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#To find out how many records are malignant and how many are benign in the Input dataset\n",
    "data['class'].value_counts() #Binary Variable\n",
    "print(data['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# To Know the target names or the Labels of Classification Model\n",
    "print(cancer_ds.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.462830</td>\n",
       "      <td>21.604906</td>\n",
       "      <td>115.365377</td>\n",
       "      <td>978.376415</td>\n",
       "      <td>0.102898</td>\n",
       "      <td>0.145188</td>\n",
       "      <td>0.160775</td>\n",
       "      <td>0.087990</td>\n",
       "      <td>0.192909</td>\n",
       "      <td>0.062680</td>\n",
       "      <td>...</td>\n",
       "      <td>21.134811</td>\n",
       "      <td>29.318208</td>\n",
       "      <td>141.370330</td>\n",
       "      <td>1422.286321</td>\n",
       "      <td>0.144845</td>\n",
       "      <td>0.374824</td>\n",
       "      <td>0.450606</td>\n",
       "      <td>0.182237</td>\n",
       "      <td>0.323468</td>\n",
       "      <td>0.091530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.146524</td>\n",
       "      <td>17.914762</td>\n",
       "      <td>78.075406</td>\n",
       "      <td>462.790196</td>\n",
       "      <td>0.092478</td>\n",
       "      <td>0.080085</td>\n",
       "      <td>0.046058</td>\n",
       "      <td>0.025717</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>0.062867</td>\n",
       "      <td>...</td>\n",
       "      <td>13.379801</td>\n",
       "      <td>23.515070</td>\n",
       "      <td>87.005938</td>\n",
       "      <td>558.899440</td>\n",
       "      <td>0.124959</td>\n",
       "      <td>0.182673</td>\n",
       "      <td>0.166238</td>\n",
       "      <td>0.074444</td>\n",
       "      <td>0.270246</td>\n",
       "      <td>0.079442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter   mean area  mean smoothness  \\\n",
       "class                                                                           \n",
       "0        17.462830     21.604906      115.365377  978.376415         0.102898   \n",
       "1        12.146524     17.914762       78.075406  462.790196         0.092478   \n",
       "\n",
       "       mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "class                                                                         \n",
       "0              0.145188        0.160775             0.087990       0.192909   \n",
       "1              0.080085        0.046058             0.025717       0.174186   \n",
       "\n",
       "       mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "class                          ...                                \n",
       "0                    0.062680  ...     21.134811      29.318208   \n",
       "1                    0.062867  ...     13.379801      23.515070   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "class                                                                      \n",
       "0           141.370330  1422.286321          0.144845           0.374824   \n",
       "1            87.005938   558.899440          0.124959           0.182673   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "class                                                          \n",
       "0             0.450606              0.182237        0.323468   \n",
       "1             0.166238              0.074444        0.270246   \n",
       "\n",
       "       worst fractal dimension  \n",
       "class                           \n",
       "0                     0.091530  \n",
       "1                     0.079442  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To decribe the Statistical measure of Mean for different parametes of all the features of the dataset grouped by the Class/Label they belong to i.e, either 0 or 1\n",
    "data.groupby('class').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing train_test_split() function from Sklearn library\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the Input dataset into Feature Vector(X) and Target Variable(Y)\n",
    "X = data.drop('class', axis = 1)\n",
    "Y = data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Line of code to split the dataset in Training and Testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,) (426,) (143,)\n"
     ]
    }
   ],
   "source": [
    "# To print the shape of Y(Target Variable) and shape of both the Training and Testing datsets for Y(Target Variable)\n",
    "print(Y.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6274165202108963 0.6338028169014085 0.6083916083916084\n"
     ]
    }
   ],
   "source": [
    "#To print the Mean of Y(Target Variable) and Mean of both the Training and Testing datsets for Y(Target Variable)\n",
    "print(Y.mean(), Y_train.mean(), Y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius                 14.132787\n",
      "mean texture                19.353750\n",
      "mean perimeter              92.014316\n",
      "mean area                  655.512500\n",
      "mean smoothness              0.096430\n",
      "mean compactness             0.104800\n",
      "mean concavity               0.089499\n",
      "mean concave points          0.049027\n",
      "mean symmetry                0.181332\n",
      "mean fractal dimension       0.062856\n",
      "radius error                 0.405836\n",
      "texture error                1.237711\n",
      "perimeter error              2.877008\n",
      "area error                  40.405990\n",
      "smoothness error             0.007085\n",
      "compactness error            0.025915\n",
      "concavity error              0.032414\n",
      "concave points error         0.011898\n",
      "symmetry error               0.020688\n",
      "fractal dimension error      0.003863\n",
      "worst radius                16.248430\n",
      "worst texture               25.752852\n",
      "worst perimeter            107.166367\n",
      "worst area                 877.756055\n",
      "worst smoothness             0.132171\n",
      "worst compactness            0.255238\n",
      "worst concavity              0.273038\n",
      "worst concave points         0.114549\n",
      "worst symmetry               0.289508\n",
      "worst fractal dimension      0.084020\n",
      "dtype: float64 mean radius                 14.077930\n",
      "mean texture                18.713860\n",
      "mean perimeter              91.562281\n",
      "mean area                  649.289474\n",
      "mean smoothness              0.095735\n",
      "mean compactness             0.100214\n",
      "mean concavity               0.082510\n",
      "mean concave points          0.047954\n",
      "mean symmetry                0.179633\n",
      "mean fractal dimension       0.062269\n",
      "radius error                 0.399212\n",
      "texture error                1.029500\n",
      "perimeter error              2.767711\n",
      "area error                  39.718088\n",
      "smoothness error             0.006645\n",
      "compactness error            0.021552\n",
      "concavity error              0.027220\n",
      "concave points error         0.010878\n",
      "symmetry error               0.019238\n",
      "fractal dimension error      0.003181\n",
      "worst radius                16.455667\n",
      "worst texture               24.997895\n",
      "worst perimeter            108.113158\n",
      "worst area                 905.977193\n",
      "worst smoothness             0.134146\n",
      "worst compactness            0.245522\n",
      "worst concavity              0.264557\n",
      "worst concave points         0.115120\n",
      "worst symmetry               0.295174\n",
      "worst fractal dimension      0.083277\n",
      "dtype: float64 mean radius                 14.127292\n",
      "mean texture                19.289649\n",
      "mean perimeter              91.969033\n",
      "mean area                  654.889104\n",
      "mean smoothness              0.096360\n",
      "mean compactness             0.104341\n",
      "mean concavity               0.088799\n",
      "mean concave points          0.048919\n",
      "mean symmetry                0.181162\n",
      "mean fractal dimension       0.062798\n",
      "radius error                 0.405172\n",
      "texture error                1.216853\n",
      "perimeter error              2.866059\n",
      "area error                  40.337079\n",
      "smoothness error             0.007041\n",
      "compactness error            0.025478\n",
      "concavity error              0.031894\n",
      "concave points error         0.011796\n",
      "symmetry error               0.020542\n",
      "fractal dimension error      0.003795\n",
      "worst radius                16.269190\n",
      "worst texture               25.677223\n",
      "worst perimeter            107.261213\n",
      "worst area                 880.583128\n",
      "worst smoothness             0.132369\n",
      "worst compactness            0.254265\n",
      "worst concavity              0.272188\n",
      "worst concave points         0.114606\n",
      "worst symmetry               0.290076\n",
      "worst fractal dimension      0.083946\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Splitting the Input into Training(90%) and Testing(10%) datasets and using Stratify to push same number of labels into  the training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.1, stratify = Y)\n",
    "print(X_train.mean(), X_test.mean(), X.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius                 14.022119\n",
      "mean texture                19.286211\n",
      "mean perimeter              91.266348\n",
      "mean area                  645.180078\n",
      "mean smoothness              0.096583\n",
      "mean compactness             0.104042\n",
      "mean concavity               0.088249\n",
      "mean concave points          0.048288\n",
      "mean symmetry                0.181552\n",
      "mean fractal dimension       0.062889\n",
      "radius error                 0.401108\n",
      "texture error                1.223169\n",
      "perimeter error              2.837574\n",
      "area error                  39.672730\n",
      "smoothness error             0.007096\n",
      "compactness error            0.025565\n",
      "concavity error              0.032191\n",
      "concave points error         0.011840\n",
      "symmetry error               0.020756\n",
      "fractal dimension error      0.003832\n",
      "worst radius                16.121150\n",
      "worst texture               25.663828\n",
      "worst perimeter            106.244395\n",
      "worst area                 863.284766\n",
      "worst smoothness             0.132500\n",
      "worst compactness            0.253774\n",
      "worst concavity              0.271522\n",
      "worst concave points         0.113878\n",
      "worst symmetry               0.290738\n",
      "worst fractal dimension      0.084095\n",
      "dtype: float64 mean radius                  15.072000\n",
      "mean texture                 19.320526\n",
      "mean perimeter               98.280877\n",
      "mean area                   742.100000\n",
      "mean smoothness               0.094356\n",
      "mean compactness              0.107030\n",
      "mean concavity                0.093742\n",
      "mean concave points           0.054589\n",
      "mean symmetry                 0.177660\n",
      "mean fractal dimension        0.061980\n",
      "radius error                  0.441679\n",
      "texture error                 1.160121\n",
      "perimeter error               3.121930\n",
      "area error                   46.304561\n",
      "smoothness error              0.006549\n",
      "compactness error             0.024694\n",
      "concavity error               0.029222\n",
      "concave points error          0.011400\n",
      "symmetry error                0.018621\n",
      "fractal dimension error       0.003465\n",
      "worst radius                 17.598947\n",
      "worst texture                25.797544\n",
      "worst perimeter             116.394737\n",
      "worst area                 1035.964912\n",
      "worst smoothness              0.131189\n",
      "worst compactness             0.258679\n",
      "worst concavity               0.278174\n",
      "worst concave points          0.121151\n",
      "worst symmetry                0.284126\n",
      "worst fractal dimension       0.082607\n",
      "dtype: float64 mean radius                 14.127292\n",
      "mean texture                19.289649\n",
      "mean perimeter              91.969033\n",
      "mean area                  654.889104\n",
      "mean smoothness              0.096360\n",
      "mean compactness             0.104341\n",
      "mean concavity               0.088799\n",
      "mean concave points          0.048919\n",
      "mean symmetry                0.181162\n",
      "mean fractal dimension       0.062798\n",
      "radius error                 0.405172\n",
      "texture error                1.216853\n",
      "perimeter error              2.866059\n",
      "area error                  40.337079\n",
      "smoothness error             0.007041\n",
      "compactness error            0.025478\n",
      "concavity error              0.031894\n",
      "concave points error         0.011796\n",
      "symmetry error               0.020542\n",
      "fractal dimension error      0.003795\n",
      "worst radius                16.269190\n",
      "worst texture               25.677223\n",
      "worst perimeter            107.261213\n",
      "worst area                 880.583128\n",
      "worst smoothness             0.132369\n",
      "worst compactness            0.254265\n",
      "worst concavity              0.272188\n",
      "worst concave points         0.114606\n",
      "worst symmetry               0.290076\n",
      "worst fractal dimension      0.083946\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Splitting the Input into Training(90%) and Testing(10%) datasets and using random_state fixed to particular seed value so that the same record is pushed into the Training and Testing Sets at each execution \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.1, stratify = Y, random_state = 3)\n",
    "print(X_train.mean(), X_test.mean(), X.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,) (512,) (57,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the Input into Training(90%) and Testing(10%) sets and using Stratify to push same number of labels into  the training and testing sets and using random_state to fix particular seed value so that the same record is pushed into the Training and Testing Sets at each execution \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.1, stratify = Y, random_state = 3)\n",
    "print(Y.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the Input into Training(80%) and Testing(20%) sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,) (455,) (114,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,stratify = Y, random_state = 2)\n",
    "print(Y.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binarization of Input Feature Vector for both training and testing sets using pd.cut function \n",
    "X_binarised_train = X_train.apply(pd.cut, bins = 2, labels=[1,0])\n",
    "X_binarised_test = X_test.apply(pd.cut, bins=2, labels=[1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
      "23            0            1              0         0               1   \n",
      "316           1            1              1         1               1   \n",
      "251           1            1              1         1               1   \n",
      "391           1            1              1         1               1   \n",
      "444           0            1              0         1               1   \n",
      "..          ...          ...            ...       ...             ...   \n",
      "71            1            1              1         1               1   \n",
      "233           0            0              0         1               1   \n",
      "346           1            1              1         1               1   \n",
      "17            1            1              1         1               0   \n",
      "75            1            1              1         1               1   \n",
      "\n",
      "    mean compactness mean concavity mean concave points mean symmetry  \\\n",
      "23                 1              1                   1             1   \n",
      "316                1              1                   1             1   \n",
      "251                1              1                   1             1   \n",
      "391                1              1                   1             0   \n",
      "444                1              1                   1             1   \n",
      "..               ...            ...                 ...           ...   \n",
      "71                 1              1                   1             1   \n",
      "233                1              1                   1             1   \n",
      "346                1              1                   1             1   \n",
      "17                 0              1                   0             0   \n",
      "75                 1              1                   1             1   \n",
      "\n",
      "    mean fractal dimension  ... worst radius worst texture worst perimeter  \\\n",
      "23                       1  ...            0             0               0   \n",
      "316                      1  ...            1             1               1   \n",
      "251                      1  ...            1             1               1   \n",
      "391                      1  ...            1             1               1   \n",
      "444                      1  ...            1             1               1   \n",
      "..                     ...  ...          ...           ...             ...   \n",
      "71                       0  ...            1             1               1   \n",
      "233                      1  ...            0             0               0   \n",
      "346                      1  ...            1             1               1   \n",
      "17                       1  ...            1             0               1   \n",
      "75                       1  ...            1             1               1   \n",
      "\n",
      "    worst area worst smoothness worst compactness worst concavity  \\\n",
      "23           0                1                 1               1   \n",
      "316          1                1                 1               1   \n",
      "251          1                1                 1               1   \n",
      "391          1                1                 1               1   \n",
      "444          1                1                 1               1   \n",
      "..         ...              ...               ...             ...   \n",
      "71           1                1                 1               1   \n",
      "233          1                1                 1               1   \n",
      "346          1                1                 1               1   \n",
      "17           1                0                 1               1   \n",
      "75           1                0                 1               1   \n",
      "\n",
      "    worst concave points worst symmetry worst fractal dimension  \n",
      "23                     0              1                       1  \n",
      "316                    1              1                       1  \n",
      "251                    1              1                       1  \n",
      "391                    1              1                       1  \n",
      "444                    0              1                       1  \n",
      "..                   ...            ...                     ...  \n",
      "71                     1              1                       1  \n",
      "233                    0              1                       1  \n",
      "346                    1              1                       1  \n",
      "17                     0              1                       1  \n",
      "75                     0              1                       1  \n",
      "\n",
      "[455 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "#Binarised Input Feature Vector of Training set\n",
    "print(X_binarised_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
      "223           1            1              1         1               1   \n",
      "418           1            1              1         1               1   \n",
      "246           1            1              1         1               1   \n",
      "387           1            1              1         1               1   \n",
      "407           1            1              1         1               1   \n",
      "..          ...          ...            ...       ...             ...   \n",
      "467           1            1              1         1               1   \n",
      "108           0            1              0         0               0   \n",
      "430           1            0              1         1               1   \n",
      "129           0            0              0         0               1   \n",
      "188           1            1              1         1               1   \n",
      "\n",
      "    mean compactness mean concavity mean concave points mean symmetry  \\\n",
      "223                1              1                   1             1   \n",
      "418                1              1                   1             1   \n",
      "246                1              1                   1             1   \n",
      "387                1              1                   1             1   \n",
      "407                1              1                   1             1   \n",
      "..               ...            ...                 ...           ...   \n",
      "467                1              1                   1             1   \n",
      "108                0              0                   0             0   \n",
      "430                0              0                   1             1   \n",
      "129                1              0                   0             0   \n",
      "188                1              1                   1             1   \n",
      "\n",
      "    mean fractal dimension  ... worst radius worst texture worst perimeter  \\\n",
      "223                      1  ...            0             1               1   \n",
      "418                      1  ...            1             1               1   \n",
      "246                      1  ...            1             1               1   \n",
      "387                      1  ...            1             1               1   \n",
      "407                      1  ...            1             1               1   \n",
      "..                     ...  ...          ...           ...             ...   \n",
      "467                      1  ...            1             1               1   \n",
      "108                      0  ...            0             1               0   \n",
      "430                      0  ...            1             1               1   \n",
      "129                      1  ...            0             0               0   \n",
      "188                      1  ...            1             1               1   \n",
      "\n",
      "    worst area worst smoothness worst compactness worst concavity  \\\n",
      "223          1                0                 1               1   \n",
      "418          1                1                 1               1   \n",
      "246          1                1                 1               1   \n",
      "387          1                1                 1               1   \n",
      "407          1                1                 1               1   \n",
      "..         ...              ...               ...             ...   \n",
      "467          1                1                 1               1   \n",
      "108          0                0                 0               0   \n",
      "430          1                1                 0               0   \n",
      "129          0                1                 1               1   \n",
      "188          1                1                 1               1   \n",
      "\n",
      "    worst concave points worst symmetry worst fractal dimension  \n",
      "223                    0              0                       0  \n",
      "418                    1              1                       1  \n",
      "246                    1              1                       1  \n",
      "387                    1              1                       1  \n",
      "407                    1              1                       1  \n",
      "..                   ...            ...                     ...  \n",
      "467                    1              1                       1  \n",
      "108                    0              0                       1  \n",
      "430                    0              1                       0  \n",
      "129                    0              1                       1  \n",
      "188                    1              1                       1  \n",
      "\n",
      "[114 rows x 30 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binarised Input Feature Vector of Testing set\n",
    "print(X_binarised_test)\n",
    "type(X_binarised_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the Train and Test Feature Vector datasets from DataFrame type to numpy array \n",
    "X_binarised_train = X_binarised_train.values\n",
    "X_binarised_test = X_binarised_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_binarised_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction is Malignant\n",
      "Actual Outcome is Benign\n"
     ]
    }
   ],
   "source": [
    "# What are the possible values that b(threshold) can attain for the given dataset \n",
    "#checking for b(threshold) value as 10\n",
    "b=10\n",
    "#importing randit from random to generate random values from within the range of the values of the binarised Feature Vector of the training set\n",
    "from random import randint\n",
    "i = randint(0,X_binarised_train.shape[0])\n",
    "\n",
    "# Building the logic for our ML classification Model with the training data as input feeding into it \n",
    "if(np.sum(X_binarised_train[i,:])>=b):\n",
    "    print('Model Prediction is Malignant')\n",
    "else:\n",
    "    print('Model prediction is Benign')\n",
    "    \n",
    "#Building the logic to check whether Model Prediction of Label is same and accurate to the Target Variable Value for particular Feature Vector(X)    \n",
    "if(Y_train[i]==1):\n",
    "    print('Actual Outcome is Malignant')\n",
    "else:\n",
    "    print('Actual Outcome is Benign')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For b=  0 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  1 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  2 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  3 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  4 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  5 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  6 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  7 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  8 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  9 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  10 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  11 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  12 on training set, Accurate rows:  285 Accuracy=  0.6263736263736264\n",
      "For b=  13 on training set, Accurate rows:  286 Accuracy=  0.6285714285714286\n",
      "For b=  14 on training set, Accurate rows:  287 Accuracy=  0.6307692307692307\n",
      "For b=  15 on training set, Accurate rows:  288 Accuracy=  0.6329670329670329\n",
      "For b=  16 on training set, Accurate rows:  293 Accuracy=  0.643956043956044\n",
      "For b=  17 on training set, Accurate rows:  297 Accuracy=  0.6527472527472528\n",
      "For b=  18 on training set, Accurate rows:  301 Accuracy=  0.6615384615384615\n",
      "For b=  19 on training set, Accurate rows:  303 Accuracy=  0.6659340659340659\n",
      "For b=  20 on training set, Accurate rows:  311 Accuracy=  0.6835164835164835\n",
      "For b=  21 on training set, Accurate rows:  314 Accuracy=  0.6901098901098901\n",
      "For b=  22 on training set, Accurate rows:  323 Accuracy=  0.7098901098901099\n",
      "For b=  23 on training set, Accurate rows:  341 Accuracy=  0.7494505494505495\n",
      "For b=  24 on training set, Accurate rows:  353 Accuracy=  0.7758241758241758\n",
      "For b=  25 on training set, Accurate rows:  365 Accuracy=  0.8021978021978022\n",
      "For b=  26 on training set, Accurate rows:  370 Accuracy=  0.8131868131868132\n",
      "For b=  27 on training set, Accurate rows:  386 Accuracy=  0.8483516483516483\n",
      "For b=  28 on training set, Accurate rows:  383 Accuracy=  0.8417582417582418\n",
      "For b=  29 on training set, Accurate rows:  363 Accuracy=  0.7978021978021979\n",
      "For b=  30 on training set, Accurate rows:  332 Accuracy=  0.7296703296703296\n"
     ]
    }
   ],
   "source": [
    "# Accuracy = (No. of rows predicted correctly / total no. of rows)\n",
    "#Accuray Calculation with all possible values of b (ranging from 1 to 30) for the Training Set\n",
    "\n",
    "for b in range(X_binarised_train.shape[1]+1):\n",
    "    accurate_rows = 0\n",
    "    \n",
    "    for x,y in zip(X_binarised_train, Y_train):\n",
    "        y_pred = (np.sum(x)>=b)\n",
    "        accurate_rows+= (y == y_pred)\n",
    "  \n",
    "    print('For b= ',b ,'on training set, Accurate rows: ', accurate_rows , 'Accuracy= ',accurate_rows/X_binarised_train.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:- It can be noticed that for the value of b(Threshold) = 27, the ML Classification Model predicts Labels with the Highest Accuracy of 0.8483516483516483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For b=  27 on testing set, Accurate rows:  103 Accuracy=  0.9035087719298246\n"
     ]
    }
   ],
   "source": [
    "#Accuray Calculation with the derived optimum value of b = 27 for the Testing  Set\n",
    "acc_rows=0\n",
    "t=X_binarised_test.shape[0]\n",
    "b=27\n",
    "for x,y in zip(X_binarised_test, Y_test):\n",
    "        y_pred = (np.sum(x)>=b)\n",
    "        acc_rows+= (y == y_pred)\n",
    "    \n",
    "print('For b= ',b ,'on testing set, Accurate rows: ', acc_rows , 'Accuracy= ',acc_rows/t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Vs Traing Accuracy for optimum value of b=27\n",
    "For b=  27 on training set, Accurate rows:  386 Accuracy=  0.8483516483516483\n",
    "For b=  27 on testing set, Accurate rows:  103 Accuracy=  0.9035087719298246"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the Input into Training(70%) and Testing(30%) sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569,) (398,) (171,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3, stratify = Y, random_state = 3)\n",
    "print(Y.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binarization of Input Feature Vector for both training and testing sets using pd.cut function \n",
    "X_binarised_train = X_train.apply(pd.cut, bins = 2, labels=[1,0])\n",
    "X_binarised_test = X_test.apply(pd.cut, bins=2, labels=[1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
      "387           1            1              1         1               1   \n",
      "225           1            1              1         1               1   \n",
      "430           1            1              1         1               1   \n",
      "324           1            1              1         1               1   \n",
      "314           1            1              1         1               1   \n",
      "..          ...          ...            ...       ...             ...   \n",
      "166           1            1              1         1               1   \n",
      "463           1            1              1         1               1   \n",
      "358           1            1              1         1               1   \n",
      "381           1            1              1         1               1   \n",
      "127           0            1              0         1               1   \n",
      "\n",
      "    mean compactness mean concavity mean concave points mean symmetry  \\\n",
      "387                1              1                   1             1   \n",
      "225                1              1                   1             0   \n",
      "430                0              0                   1             1   \n",
      "324                1              1                   1             1   \n",
      "314                1              1                   1             0   \n",
      "..               ...            ...                 ...           ...   \n",
      "166                1              1                   1             1   \n",
      "463                1              1                   1             1   \n",
      "358                1              1                   1             1   \n",
      "381                1              1                   1             1   \n",
      "127                1              1                   1             1   \n",
      "\n",
      "    mean fractal dimension  ... worst radius worst texture worst perimeter  \\\n",
      "387                      1  ...            1             1               1   \n",
      "225                      1  ...            1             1               1   \n",
      "430                      1  ...            1             1               1   \n",
      "324                      1  ...            1             1               1   \n",
      "314                      1  ...            1             1               1   \n",
      "..                     ...  ...          ...           ...             ...   \n",
      "166                      1  ...            1             1               1   \n",
      "463                      1  ...            1             1               1   \n",
      "358                      1  ...            1             1               1   \n",
      "381                      1  ...            1             1               1   \n",
      "127                      1  ...            1             1               1   \n",
      "\n",
      "    worst area worst smoothness worst compactness worst concavity  \\\n",
      "387          1                1                 1               1   \n",
      "225          1                1                 1               1   \n",
      "430          1                1                 0               0   \n",
      "324          1                1                 1               1   \n",
      "314          1                1                 1               1   \n",
      "..         ...              ...               ...             ...   \n",
      "166          1                1                 1               1   \n",
      "463          1                1                 1               1   \n",
      "358          1                1                 1               1   \n",
      "381          1                1                 1               1   \n",
      "127          1                1                 1               1   \n",
      "\n",
      "    worst concave points worst symmetry worst fractal dimension  \n",
      "387                    1              1                       1  \n",
      "225                    1              1                       1  \n",
      "430                    0              1                       1  \n",
      "324                    1              1                       1  \n",
      "314                    1              1                       1  \n",
      "..                   ...            ...                     ...  \n",
      "166                    1              1                       1  \n",
      "463                    1              1                       1  \n",
      "358                    1              1                       1  \n",
      "381                    1              1                       1  \n",
      "127                    1              1                       1  \n",
      "\n",
      "[398 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "#Binarised Input Feature Vector of Training set\n",
    "print(X_binarised_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
      "153           1            1              1         1               1   \n",
      "48            1            1              1         1               0   \n",
      "163           1            0              1         1               1   \n",
      "371           1            1              1         1               1   \n",
      "340           1            1              1         1               1   \n",
      "..          ...          ...            ...       ...             ...   \n",
      "106           1            1              1         1               0   \n",
      "280           0            0              0         1               1   \n",
      "491           0            1              1         1               1   \n",
      "24            1            1              1         1               0   \n",
      "515           1            1              1         1               0   \n",
      "\n",
      "    mean compactness mean concavity mean concave points mean symmetry  \\\n",
      "153                1              1                   1             1   \n",
      "48                 1              1                   1             1   \n",
      "163                1              1                   1             1   \n",
      "371                1              1                   1             1   \n",
      "340                1              1                   1             0   \n",
      "..               ...            ...                 ...           ...   \n",
      "106                1              1                   1             1   \n",
      "280                1              1                   0             1   \n",
      "491                1              1                   1             1   \n",
      "24                 1              1                   0             0   \n",
      "515                1              1                   1             0   \n",
      "\n",
      "    mean fractal dimension  ... worst radius worst texture worst perimeter  \\\n",
      "153                      1  ...            1             1               1   \n",
      "48                       1  ...            1             1               1   \n",
      "163                      1  ...            1             1               1   \n",
      "371                      1  ...            1             1               1   \n",
      "340                      1  ...            1             1               1   \n",
      "..                     ...  ...          ...           ...             ...   \n",
      "106                      1  ...            1             1               1   \n",
      "280                      1  ...            0             0               0   \n",
      "491                      1  ...            1             1               1   \n",
      "24                       1  ...            0             0               0   \n",
      "515                      1  ...            1             1               1   \n",
      "\n",
      "    worst area worst smoothness worst compactness worst concavity  \\\n",
      "153          1                1                 1               1   \n",
      "48           1                1                 1               1   \n",
      "163          1                1                 1               1   \n",
      "371          1                1                 1               1   \n",
      "340          1                1                 1               1   \n",
      "..         ...              ...               ...             ...   \n",
      "106          1                0                 1               1   \n",
      "280          1                0                 1               1   \n",
      "491          1                1                 1               1   \n",
      "24           0                0                 1               1   \n",
      "515          1                1                 1               1   \n",
      "\n",
      "    worst concave points worst symmetry worst fractal dimension  \n",
      "153                    1              1                       1  \n",
      "48                     1              1                       1  \n",
      "163                    1              1                       1  \n",
      "371                    1              1                       1  \n",
      "340                    1              1                       1  \n",
      "..                   ...            ...                     ...  \n",
      "106                    1              1                       1  \n",
      "280                    0              1                       1  \n",
      "491                    1              1                       1  \n",
      "24                     0              0                       1  \n",
      "515                    1              1                       1  \n",
      "\n",
      "[171 rows x 30 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binarised Input Feature Vector of Testing set\n",
    "print(X_binarised_test)\n",
    "type(X_binarised_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the Train and Test Feature Vector datasets from DataFrame type to numpy array \n",
    "X_binarised_train = X_binarised_train.values\n",
    "X_binarised_test = X_binarised_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_binarised_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For b=  0 on training set, Accurate rows:  250 Accuracy=  0.628140703517588\n",
      "For b=  1 on training set, Accurate rows:  250 Accuracy=  0.628140703517588\n",
      "For b=  2 on training set, Accurate rows:  250 Accuracy=  0.628140703517588\n",
      "For b=  3 on training set, Accurate rows:  250 Accuracy=  0.628140703517588\n",
      "For b=  4 on training set, Accurate rows:  250 Accuracy=  0.628140703517588\n",
      "For b=  5 on training set, Accurate rows:  250 Accuracy=  0.628140703517588\n",
      "For b=  6 on training set, Accurate rows:  250 Accuracy=  0.628140703517588\n",
      "For b=  7 on training set, Accurate rows:  250 Accuracy=  0.628140703517588\n",
      "For b=  8 on training set, Accurate rows:  250 Accuracy=  0.628140703517588\n",
      "For b=  9 on training set, Accurate rows:  250 Accuracy=  0.628140703517588\n",
      "For b=  10 on training set, Accurate rows:  250 Accuracy=  0.628140703517588\n",
      "For b=  11 on training set, Accurate rows:  250 Accuracy=  0.628140703517588\n",
      "For b=  12 on training set, Accurate rows:  252 Accuracy=  0.6331658291457286\n",
      "For b=  13 on training set, Accurate rows:  254 Accuracy=  0.6381909547738693\n",
      "For b=  14 on training set, Accurate rows:  254 Accuracy=  0.6381909547738693\n",
      "For b=  15 on training set, Accurate rows:  256 Accuracy=  0.6432160804020101\n",
      "For b=  16 on training set, Accurate rows:  257 Accuracy=  0.6457286432160804\n",
      "For b=  17 on training set, Accurate rows:  261 Accuracy=  0.6557788944723618\n",
      "For b=  18 on training set, Accurate rows:  263 Accuracy=  0.6608040201005025\n",
      "For b=  19 on training set, Accurate rows:  265 Accuracy=  0.6658291457286433\n",
      "For b=  20 on training set, Accurate rows:  269 Accuracy=  0.6758793969849246\n",
      "For b=  21 on training set, Accurate rows:  274 Accuracy=  0.6884422110552764\n",
      "For b=  22 on training set, Accurate rows:  282 Accuracy=  0.7085427135678392\n",
      "For b=  23 on training set, Accurate rows:  287 Accuracy=  0.7211055276381909\n",
      "For b=  24 on training set, Accurate rows:  303 Accuracy=  0.7613065326633166\n",
      "For b=  25 on training set, Accurate rows:  313 Accuracy=  0.7864321608040201\n",
      "For b=  26 on training set, Accurate rows:  328 Accuracy=  0.8241206030150754\n",
      "For b=  27 on training set, Accurate rows:  339 Accuracy=  0.8517587939698492\n",
      "For b=  28 on training set, Accurate rows:  337 Accuracy=  0.8467336683417085\n",
      "For b=  29 on training set, Accurate rows:  320 Accuracy=  0.8040201005025126\n",
      "For b=  30 on training set, Accurate rows:  297 Accuracy=  0.7462311557788944\n"
     ]
    }
   ],
   "source": [
    "# Accuracy = (No. of rows predicted correctly / total no. of rows)\n",
    "#Accuray Calculation with all possible values of b (ranging from 1 to 30) for the Training Set \n",
    "for b in range(X_binarised_train.shape[1]+1):\n",
    "    accurate_rows = 0\n",
    "    \n",
    "    for x,y in zip(X_binarised_train, Y_train):\n",
    "        y_pred = (np.sum(x)>=b)\n",
    "        accurate_rows+= (y == y_pred)\n",
    "  \n",
    "    print('For b= ',b ,'on training set, Accurate rows: ', accurate_rows , 'Accuracy= ',accurate_rows/X_binarised_train.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:- It can be noticed that for the value of b(Threshold) = 27, the ML Classification Model predicts Labels with the Highest Accuracy of 0.8517587939698492 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For b=  27 on testing set, Accurate rows:  148 Accuracy=  0.8654970760233918\n"
     ]
    }
   ],
   "source": [
    "#Accuray Calculation with the derived optimum value of b = 27 for the Testing  Set\n",
    "acc_rows=0\n",
    "t=X_binarised_test.shape[0]\n",
    "b=27\n",
    "for x,y in zip(X_binarised_test, Y_test):\n",
    "        y_pred = (np.sum(x)>=b)\n",
    "        acc_rows+= (y == y_pred)\n",
    "    \n",
    "print('For b= ',b ,'on testing set, Accurate rows: ', acc_rows , 'Accuracy= ',acc_rows/t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Vs Traing Accuracy for optimum value of  b=27\n",
    "For b=  27 on training set, Accurate rows:  339 Accuracy=  0.8517587939698492\n",
    "For b=  27 on testing set, Accurate rows:  148 Accuracy=  0.8654970760233918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
